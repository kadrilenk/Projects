{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021\n",
    "month = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'data/news-{year}-{month:02d}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text):\n",
    "    try:\n",
    "        # there is a max 5000 char limit that can be translated at once\n",
    "        max_char = 4999\n",
    "\n",
    "        if len(text) == 0:\n",
    "            return ''\n",
    "        elif len(text) > max_char:\n",
    "            text_list = []\n",
    "            start = 0\n",
    "            end = text[start:max_char].rfind('.')+1\n",
    "\n",
    "            while start != end:\n",
    "                text_list.append(text[start:end].strip())\n",
    "                start = end\n",
    "                end += text[end:end+max_char].rfind('.')+1\n",
    "\n",
    "            translated_list = GoogleTranslator(source='et', target='en').translate_batch(text_list)\n",
    "            return ' '.join(translated_list)\n",
    "\n",
    "        else:\n",
    "            return GoogleTranslator(source='et', target='en').translate(text)\n",
    "    except:\n",
    "        return 'Something went wrong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_list_est = list(df['articleText'])\n",
    "lead_list_est = list(df['lead'])\n",
    "head_list_est = list(df['heading'])\n",
    "\n",
    "text_list_eng = []\n",
    "lead_list_eng = []\n",
    "head_list_eng = []\n",
    "\n",
    "for h, l, t in zip(head_list_est, lead_list_est, text_list_est):\n",
    "# for h in head_list_est:\n",
    "    h_eng = translate_text(h)\n",
    "    l_eng = translate_text(l)\n",
    "    t_eng = translate_text(t)\n",
    "    \n",
    "    head_list_eng.append(h_eng)\n",
    "    lead_list_eng.append(l_eng)\n",
    "    text_list_eng.append(t_eng)\n",
    "    \n",
    "    now = datetime.datetime.now().strftime(format='%H:%M:%S')\n",
    "    percent = round(len(head_list_eng)/len(head_list_est)*100, 4)\n",
    "    \n",
    "    b = h_eng == 'Something went wrong'\n",
    "    \n",
    "    print(f'{now} {b} {len(head_list_eng)}/{len(head_list_est)} {percent}%')\n",
    "    \n",
    "df['headingEng'] = head_list_eng\n",
    "df['leadEng'] = lead_list_eng\n",
    "df['articleTextEng'] = text_list_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    try:\n",
    "        return ' '.join([token.lemma_ for token in nlp(text.lower()) if token.pos_ in ['NOUN','ADJ','VERB','ADV']])\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['headingEngLemma'] = df['headingEng'].apply(lemmatize)\n",
    "df['leadEngLemma'] = df['leadEng'].apply(lemmatize)\n",
    "df['articleTextEngLemma'] = df['articleTextEng'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id', 'publishDate', 'updatedDate', 'url', 'headingEng', 'leadEng', 'articleTextEng',\n",
    "       'headingEngLemma', 'leadEngLemma', 'articleTextEngLemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols].to_csv(f'data/news-eng-lemmatized-{year}-{month:02d}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df.loc[df['headingEng']=='Something went wrong']))\n",
    "print(len(df.loc[df['leadEng']=='Something went wrong']))\n",
    "print(len(df.loc[df['articleTextEng']=='Something went wrong']))\n",
    "\n",
    "print(len(df.loc[df['headingEngLemma']=='go wrong']))\n",
    "print(len(df.loc[df['leadEngLemma']=='go wrong']))\n",
    "print(len(df.loc[df['articleTextEngLemma']=='go wrong']))\n",
    "\n",
    "# 0\n",
    "# 248\n",
    "# 311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
